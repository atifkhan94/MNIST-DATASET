{
    "cells": [{
                "cell_type": "markdown",
                "metadata": {},
                "source": ["# MNIST Digit Classification with PyTorch\n",
                    "\n",
                    "This notebook demonstrates how to build and train a neural network for classifying handwritten digits from the MNIST dataset using PyTorch. We'll go through the following steps:\n",
                    "\n",
                    "1. Data Loading and Preprocessing\n",
                    "2. Model Architecture\n",
                    "3. Training Process and Accuracy Tracking\n",
                    "4. Model Evaluation and Performance Metrics\n",
                    "5. Sample Predictions\n"
                ]
            },
            {
                "cell_type": "code",
                "execution_count": null,
                "metadata": {},
                "source": ["import torch\n",
                    "import torch.nn as nn\n",
                    "import torch.optim as optim\n",
                    "from torch.utils.data import TensorDataset, DataLoader\n",
                    "import numpy as np\n",
                    "import matplotlib.pyplot as plt\n",
                    "import seaborn as sns\n",
                    "from sklearn.metrics import confusion_matrix, classification_report\n",
                    "from mnist_loader import load_mnist\n",
                    "\n",
                    "# Set random seed for reproducibility\n",
                    "torch.manual_seed(42)\n",
                    "\n",
                    "# Set style for better visualizations\n",
                    "plt.style.use('seaborn')"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": ["## 1. Data Loading and Preprocessing\n",
                    "\n",
                    "First, we'll load the MNIST dataset and preprocess it for training. The images will be normalized and reshaped into the appropriate format."
                ]
            },
            {
                "cell_type": "code",
                "execution_count": null,
                "metadata": {},
                "source": ["# Load MNIST data\n",
                    "(train_images, train_labels), (test_images, test_labels) = load_mnist()\n",
                    "\n",
                    "# Convert numpy arrays to PyTorch tensors\n",
                    "train_images = torch.FloatTensor(train_images.reshape(-1, 784))\n",
                    "train_labels = torch.LongTensor(train_labels)\n",
                    "test_images = torch.FloatTensor(test_images.reshape(-1, 784))\n",
                    "test_labels = torch.LongTensor(test_labels)\n",
                    "\n",
                    "# Create data loaders\n",
                    "train_dataset = TensorDataset(train_images, train_labels)\n",
                    "test_dataset = TensorDataset(test_images, test_labels)\n",
                    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
                    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": ["Let's visualize some sample images from the dataset to better understand what we're working with."]
            },
            {
                "cell_type": "code",
                "execution_count": null,
                "metadata": {},
                "source": ["def show_images(images, labels, num_images=5):\n",
                    "    fig, axes = plt.subplots(1, num_images, figsize=(12, 3))\n",
                    "    for i in range(num_images):\n",
                    "        img = images[i].reshape(28, 28)\n",
                    "        axes[i].imshow(img, cmap='gray')\n",
                    "        axes[i].set_title(f'Label: {labels[i]}')\n",
                    "        axes[i].axis('off')\n",
                    "    plt.show()\n",
                    "\n",
                    "# Display sample images\n",
                    "show_images(train_images.numpy(), train_labels.numpy())"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": ["## 2. Model Architecture\n",
                    "\n",
                    "We'll create a neural network with multiple fully connected layers and dropout for regularization."
                ]
            },
            {
                "cell_type": "code",
                "execution_count": null,
                "metadata": {},
                "source": ["class MNISTClassifier(nn.Module):\n",
                    "    def __init__(self):\n",
                    "        super(MNISTClassifier, self).__init__()\n",
                    "        self.model = nn.Sequential(\n",
                    "            nn.Linear(784, 128),\n",
                    "            nn.ReLU(),\n",
                    "            nn.Dropout(0.2),\n",
                    "            nn.Linear(128, 64),\n",
                    "            nn.ReLU(),\n",
                    "            nn.Dropout(0.2),\n",
                    "            nn.Linear(64, 10)\n",
                    "        )\n",
                    "\n",
                    "    def forward(self, x):\n",
                    "        return self.model(x)\n",
                    "\n",
                    "# Initialize model, loss function, and optimizer\n",
                    "model = MNISTClassifier()\n",
                    "criterion = nn.CrossEntropyLoss()\n",
                    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": ["## 3. Training Process and Accuracy Tracking\n",
                    "\n",
                    "Now we'll train the model while tracking both loss and accuracy metrics for each epoch."
                ]
            },
            {
                "cell_type": "code",
                "execution_count": null,
                "metadata": {},
                "source": ["def train(epochs):\n",
                    "    train_losses = []\n",
                    "    train_accuracies = []\n",
                    "    best_accuracy = 0\n",
                    "    \n",
                    "    for epoch in range(epochs):\n",
                    "        model.train()\n",
                    "        total_loss = 0\n",
                    "        correct = 0\n",
                    "        total = 0\n",
                    "\n",
                    "        for images, labels in train_loader:\n",
                    "            optimizer.zero_grad()\n",
                    "            outputs = model(images)\n",
                    "            loss = criterion(outputs, labels)\n",
                    "            loss.backward()\n",
                    "            optimizer.step()\n",
                    "\n",
                    "            total_loss += loss.item()\n",
                    "            _, predicted = torch.max(outputs.data, 1)\n",
                    "            total += labels.size(0)\n",
                    "            correct += (predicted == labels).sum().item()\n",
                    "\n",
                    "        accuracy = 100 * correct / total\n",
                    "        avg_loss = total_loss / len(train_loader)\n",
                    "        train_losses.append(avg_loss)\n",
                    "        train_accuracies.append(accuracy)\n",
                    "        \n",
                    "        print(f'Epoch [{epoch+1}/{epochs}]')\n",
                    "        print(f'Training Loss: {avg_loss:.4f}')\n",
                    "        print(f'Training Accuracy: {accuracy:.2f}%\n')\n",
                    "        \n",
                    "        # Track best accuracy\n",
                    "        if accuracy > best_accuracy:\n",
                    "            best_accuracy = accuracy\n",
                    "            print(f'New best training accuracy: {best_accuracy:.2f}%\n')\n",
                    "    \n",
                    "    return train_losses, train_accuracies\n",
                    "\n",
                    "# Train the model\n",
                    "print('Starting training...\n')\n",
                    "train_losses, train_accuracies = train(epochs=10)"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": ["Let's visualize the training progress with detailed metrics:"]
            },
            {
                "cell_type": "code",
                "execution_count": null,
                "metadata": {},
                "source": ["plt.figure(figsize=(15, 5))\n",
                    "\n",
                    "# Plot training loss\n",
                    "plt.subplot(1, 2, 1)\n",
                    "plt.plot(train_losses, 'b-', label='Training Loss')\n",
                    "plt.title('Training Loss Over Time')\n",
                    "plt.xlabel('Epoch')\n",
                    "plt.ylabel('Loss')\n",
                    "plt.grid(True)\n",
                    "plt.legend()\n",
                    "\n",
                    "# Plot training accuracy\n",
                    "plt.subplot(1, 2, 2)\n",
                    "plt.plot(train_accuracies, 'g-', label='Training Accuracy')\n",
                    "plt.title('Training Accuracy Over Time')\n",
                    "plt.xlabel('Epoch')\n",
                    "plt.ylabel('Accuracy (%)')\n",
                    "plt.grid(True)\n",
                    "plt.legend()\n",
                    "\n",
                    "plt.tight_layout()\n",
                    "plt.show()\n",
                    "\n",
                    "# Print final training metrics\n",
                    "print(f'Final Training Loss: {train_losses[-1]:.4f}')\n",
                    "print(f'Final Training Accuracy: {train_accuracies[-1]:.2f}%')"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": ["## 4. Model Evaluation and Performance Metrics\n",
                    "\n",
                    "Let's evaluate the model's performance on the test set with detailed metrics including:\n",
                    "- Overall accuracy\n",
                    "- Confusion matrix\n",
                    "- Per-class precision, recall, and F1-score"
                ]
            },
            {
                "cell_type": "code",
                "execution_count": null,
                "metadata": {},
                "source": ["def evaluate():\n",
                    "    model.eval()\n",
                    "    correct = 0\n",
                    "    total = 0\n",
                    "    all_predictions = []\n",
                    "    all_labels = []\n",
                    "    \n",
                    "    with torch.no_grad():\n",
                    "        for images, labels in test_loader:\n",
                    "            outputs = model(images)\n",
                    "            _, predicted = torch.max(outputs.data, 1)\n",
                    "            total += labels.size(0)\n",
                    "            correct += (predicted == labels).sum().item()\n",
                    "            all_predictions.extend(predicted.numpy())\n",
                    "            all_labels.extend(labels.numpy())\n",
                    "\n",
                    "    # Calculate overall accuracy\n",
                    "    accuracy = 100 * correct / total\n",
                    "    print('Model Performance Metrics:\n')\n",
                    "    print(f'Overall Test Accuracy: {accuracy:.2f}%\n')\n",
                    "    \n",
                    "    # Create and plot confusion matrix\n",
                    "    cm = confusion_matrix(all_labels, all_predictions)\n",
                    "    plt.figure(figsize=(10, 8))\n",
                    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
                    "    plt.title('Confusion Matrix')\n",
                    "    plt.xlabel('Predicted Label')\n",
                    "    plt.ylabel('True Label')\n",
                    "    plt.show()\n",
                    "    \n",
                    "    # Print detailed classification report\n",
                    "    print('Detailed Performance Metrics by Class:\n')\n",
                    "    print(classification_report(all_labels, all_predictions, digits=4))\n",
                    "    \n",
                    "    return all_predictions, accuracy\n",
                    "\n",
                    "print('Evaluating model performance...\n')\n",
                    "predictions, test_accuracy = evaluate()"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": ["## 5. Sample Predictions\n",
                    "\n",
                    "Let's visualize some predictions from the test set, highlighting correct and incorrect classifications:"
                ]
            },
            {
                "cell_type": "code",
                "execution_count": null,
                "metadata": {},
                "source": ["def show_predictions(images, labels, predictions, num_images=5):\n",
                        "    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n",
                        "    for i in range(num_images):\n",
                        "        img = images[i].reshape(28, 28)\n",
                        "        axes[i].imshow(img, cmap='gray')\n",
                        "        color = 'green' if predictions[i] == labels[i] else 'red'\n",
                        "        axes[i].set_title(